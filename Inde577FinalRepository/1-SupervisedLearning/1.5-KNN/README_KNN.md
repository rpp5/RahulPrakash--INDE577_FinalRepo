# K-Nearest Neighbors (KNN)

K-Nearest Neighbors (KNN) is a simple, non-parametric, and versatile algorithm used for both classification and regression. It operates by calculating the distance (often Euclidean) between a query example and all the examples in the training dataset, then selecting the nearest k examples (neighbors), where k is a user-defined constant. The prediction is made based on the predominant class among the neighbors for classification tasks, or the average for regression. KNN is highly effective for applications where the decision boundary is very irregular, making it a popular choice for many practical machine learning tasks, particularly those involving pattern recognition or recommendation systems.
